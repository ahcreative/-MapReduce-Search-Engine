{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Loading dataset\n"
      ],
      "metadata": {
        "id": "6J76bLXCF18v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iBffOKnn2qHD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "369e3dae-4438-43d5-8435-72c701183106"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "     ARTICLE_ID                 TITLE                 SECTION_TITLE  \\\n",
            "0             0             Anarchism                  Introduction   \n",
            "1             0             Anarchism     Etymology and terminology   \n",
            "2             0             Anarchism                       History   \n",
            "3             0             Anarchism  Anarchist schools of thought   \n",
            "4             0             Anarchism   Internal issues and debates   \n",
            "..          ...                   ...                           ...   \n",
            "495          42                 Algae                External links   \n",
            "496          43  Analysis of variance                  Introduction   \n",
            "497          43  Analysis of variance                       History   \n",
            "498          43  Analysis of variance            Motivating example   \n",
            "499          43  Analysis of variance    Background and terminology   \n",
            "\n",
            "                                          SECTION_TEXT  \n",
            "0    \\n\\n\\n\\n\\n\\n'''Anarchism''' is a political phi...  \n",
            "1    \\n\\nThe term ''anarchism'' is a compound word ...  \n",
            "2    \\n\\n===Origins===\\nWoodcut from a Diggers docu...  \n",
            "3    \\nPortrait of philosopher Pierre-Joseph Proudh...  \n",
            "4    \\nconsistent with anarchist values is a contro...  \n",
            "..                                                 ...  \n",
            "495  \\n\\n*  – a database of all algal names includi...  \n",
            "496  \\n\\n'''Analysis of variance''' ('''ANOVA''') i...  \n",
            "497  While the analysis of variance reached fruitio...  \n",
            "498  No fit.Fair fitVery good fitThe analysis of va...  \n",
            "499  ANOVA is a particular form of statistical hypo...  \n",
            "\n",
            "[500 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# File path to your CSV file\n",
        "file_path = '/content/drive/My Drive/enwiki-20170820.csv'\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv(file_path, nrows=500)  # Load only the first 100 rows\n",
        "\n",
        "\n",
        "\n",
        "# Print the loaded data\n",
        "print(data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing of dataset"
      ],
      "metadata": {
        "id": "9TNTpipsF6pS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "import re\n",
        "from textblob import TextBlob\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "\n",
        "# Keep only the 'ARTICLE_ID' and 'SECTION_TEXT' columns\n",
        "data = data[['ARTICLE_ID', 'SECTION_TEXT']]\n",
        "\n",
        "# Function for basic text cleaning\n",
        "def clean_text(text):\n",
        "    # Remove HTML tags\n",
        "    clean_text = re.sub(r'<.*?>', '', text)\n",
        "    # Convert text to lowercase\n",
        "    clean_text = clean_text.lower()\n",
        "    return clean_text\n",
        "\n",
        "# Apply basic text cleaning to 'SECTION_TEXT' column\n",
        "data['cleaned_text'] = data['SECTION_TEXT'].apply(clean_text)\n",
        "\n",
        "# Tokenize each entry in the 'cleaned_text' column\n",
        "data['tokens'] = data['cleaned_text'].apply(word_tokenize)\n",
        "\n",
        "# Get the list of English stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Function to remove stopwords from a list of tokens\n",
        "def remove_stopwords(tokens):\n",
        "    return [word for word in tokens if word not in stop_words]\n",
        "\n",
        "# Remove stopwords from the tokens\n",
        "data['tokens_without_stopwords'] = data['tokens'].apply(remove_stopwords)\n",
        "\n",
        "# Initialize PorterStemmer for stemming\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Initialize WordNetLemmatizer for lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Function to perform stemming on a list of tokens\n",
        "def stem_tokens(tokens):\n",
        "    return [stemmer.stem(token) for token in tokens]\n",
        "\n",
        "# Function to perform lemmatization on a list of tokens\n",
        "def lemmatize_tokens(tokens):\n",
        "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "# Apply stemming to the tokens without stopwords\n",
        "data['stemmed_tokens'] = data['tokens_without_stopwords'].apply(stem_tokens)\n",
        "\n",
        "# Apply lemmatization to the tokens without stopwords\n",
        "data['lemmatized_tokens'] = data['tokens_without_stopwords'].apply(lemmatize_tokens)\n",
        "\n",
        "# Print the preprocessed data\n",
        "print(data[['ARTICLE_ID', 'lemmatized_tokens']])\n",
        "print(data[['SECTION_TEXT','lemmatized_tokens']])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWCR49O-wBS5",
        "outputId": "c6021439-74c8-4002-a5e8-9dbe6a3a75c0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     ARTICLE_ID                                  lemmatized_tokens\n",
            "0             0  ['', 'anarchism, '', ', political, philosophy,...\n",
            "1             0  [term, ``, anarchism, '', compound, word, comp...\n",
            "2             0  [===origins===, woodcut, digger, document, wil...\n",
            "3             0  [portrait, philosopher, pierre-joseph, proudho...\n",
            "4             0  [consistent, anarchist, value, controversial, ...\n",
            "..          ...                                                ...\n",
            "495          42  [*, –, database, algal, name, including, image...\n",
            "496          43  ['', 'analysis, variance, '', ', (, ``, 'anova...\n",
            "497          43  [analysis, variance, reached, fruition, 20th, ...\n",
            "498          43  [fit.fair, fitvery, good, fitthe, analysis, va...\n",
            "499          43  [anova, particular, form, statistical, hypothe...\n",
            "\n",
            "[500 rows x 2 columns]\n",
            "                                          SECTION_TEXT  \\\n",
            "0    \\n\\n\\n\\n\\n\\n'''Anarchism''' is a political phi...   \n",
            "1    \\n\\nThe term ''anarchism'' is a compound word ...   \n",
            "2    \\n\\n===Origins===\\nWoodcut from a Diggers docu...   \n",
            "3    \\nPortrait of philosopher Pierre-Joseph Proudh...   \n",
            "4    \\nconsistent with anarchist values is a contro...   \n",
            "..                                                 ...   \n",
            "495  \\n\\n*  – a database of all algal names includi...   \n",
            "496  \\n\\n'''Analysis of variance''' ('''ANOVA''') i...   \n",
            "497  While the analysis of variance reached fruitio...   \n",
            "498  No fit.Fair fitVery good fitThe analysis of va...   \n",
            "499  ANOVA is a particular form of statistical hypo...   \n",
            "\n",
            "                                     lemmatized_tokens  \n",
            "0    ['', 'anarchism, '', ', political, philosophy,...  \n",
            "1    [term, ``, anarchism, '', compound, word, comp...  \n",
            "2    [===origins===, woodcut, digger, document, wil...  \n",
            "3    [portrait, philosopher, pierre-joseph, proudho...  \n",
            "4    [consistent, anarchist, value, controversial, ...  \n",
            "..                                                 ...  \n",
            "495  [*, –, database, algal, name, including, image...  \n",
            "496  ['', 'analysis, variance, '', ', (, ``, 'anova...  \n",
            "497  [analysis, variance, reached, fruition, 20th, ...  \n",
            "498  [fit.fair, fitvery, good, fitthe, analysis, va...  \n",
            "499  [anova, particular, form, statistical, hypothe...  \n",
            "\n",
            "[500 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# File path for the new file\n",
        "output_file_path = '/content/drive/My Drive/preprocessed_data.csv'\n",
        "\n",
        "# Save the preprocessed data to a new CSV file\n",
        "data.to_csv(output_file_path, index=False)\n",
        "\n",
        "print(\"Preprocessed data saved successfully to:\", output_file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phdysUcWHV7y",
        "outputId": "9584bc32-2b33-4650-cb44-d0fd18b41f52"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Preprocessed data saved successfully to: /content/drive/My Drive/preprocessed_data.csv\n"
          ]
        }
      ]
    }
  ]
}